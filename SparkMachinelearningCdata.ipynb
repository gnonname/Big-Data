{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkMachinelearningCdata.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMA2jkljcORI/YPwl3xnKTt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnonname/Big-Data/blob/main/SparkMachinelearningCdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "✅::::::\n",
        "\n",
        "## My first Linear Regression model with PySpark\n",
        "▶\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0mGZ7WG2Shqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation's Step"
      ],
      "metadata": {
        "id": "Y6sfKYm6SoHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqiVWdGjSJXh"
      },
      "outputs": [],
      "source": [
        "# Takes some minutes\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j ### Important for all you needeed"
      ],
      "metadata": {
        "id": "MFiqSPTRTFnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "import findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "AWVP8xFISn4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Needed librairies"
      ],
      "metadata": {
        "id": "vbiYbgqwVYOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.shell import spark"
      ],
      "metadata": {
        "id": "G8Ni_p9BVXrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Session = SparkSession.builder.appName('lm').getOrCreate()\n"
      ],
      "metadata": {
        "id": "a7sRfeERSnye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv(\"/content/ecommerce.csv\",\n",
        "                      inferSchema =True,header=True)"
      ],
      "metadata": {
        "id": "FaNx_TbsSntZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "id": "MMoJpmoUSnnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "tRkt23BBSneD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "id": "vtt5QobPahIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().show()"
      ],
      "metadata": {
        "id": "REVLNw3XawvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up my Data for the fucture model"
      ],
      "metadata": {
        "id": "fHC-v89vZ1mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "VxuIjlhmoFLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_var = ['Avg Session Length', \"Time on App\",'Time on Website','Length of Membership']\n",
        "assembler = VectorAssembler(inputCols= coef_var,outputCol='features')"
      ],
      "metadata": {
        "id": "KFIFL0xIZ_Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = assembler.transform(data)"
      ],
      "metadata": {
        "id": "jHQyUdQIZ_9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Data=output.select(\"features\", \"Yearly Amount Spent\")\n"
      ],
      "metadata": {
        "id": "gniIe718Z_6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyTrain, Mytest = Final_Data.randomSplit([0.7,0.3])"
      ],
      "metadata": {
        "id": "hhvdY_lIZ_3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mytest.describe().show()"
      ],
      "metadata": {
        "id": "wM-ifgZ2Z_0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyTrain.describe().show()"
      ],
      "metadata": {
        "id": "p3jBSbROZ_t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "1DEbeUJrZ_qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = LinearRegression(labelCol=\"Yearly Amount Spent\")"
      ],
      "metadata": {
        "id": "W7YuG_LkxCej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lm.fit(MyTrain)"
      ],
      "metadata": {
        "id": "cQOi2jQkxCbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "H-XAZ1J_xCYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"Coefficients\":model.coefficients}, index = coef_var)"
      ],
      "metadata": {
        "id": "Ph_zxM-LxCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result =model.evaluate(Mytest)"
      ],
      "metadata": {
        "id": "B1YnUA-JxCSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.residuals.show()"
      ],
      "metadata": {
        "id": "C-7XOpHxxCFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_data = Mytest.select('features')"
      ],
      "metadata": {
        "id": "WR318bmE1M5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(unlabeled_data)"
      ],
      "metadata": {
        "id": "SLxx_Upd1My3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "id": "lSxKxC0Y1MuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"**********  Model ************\\n\\n\")\n",
        "\n",
        "print(\"MAE:\", result.meanAbsoluteError)\n",
        "print(\"------------------------------\\n\\n\")\n",
        "print(\"MSE:\", result.meanSquaredError)\n",
        "print(\"------------------------------\\n\\n\")\n",
        "print(\"RMSE:\", result.rootMeanSquaredError)\n",
        "print(\"------------------------------\\n\\n\")\n",
        "print(\"R 2:\", result.r2)\n",
        "print(\"------------------------------\\n\\n\")\n",
        "print(\"R 2 ajusté:\", result.r2adj)\n",
        "print(\"------------------------------\\n\\n\")"
      ],
      "metadata": {
        "id": "El7G513d1MjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Mens"
      ],
      "metadata": {
        "id": "q1lqNRtyDgmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/apache/spark/master/data/mllib/sample_kmeans_data.txt >> sample_kmeans_data.txt"
      ],
      "metadata": {
        "id": "BpdS2W8imT_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt >> seeds_dataset.txt"
      ],
      "metadata": {
        "id": "QjQFB8YymZyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eyzxReH8xKq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ],
      "metadata": {
        "id": "7iRyGYGWkwkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"myKmensCluster\").getOrCreate()"
      ],
      "metadata": {
        "id": "vgzOzL9k1L4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xxXo7i1G1L-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"libsvm\").load(\"sample_kmeans_data.txt\")"
      ],
      "metadata": {
        "id": "kZ6Iwr4KmnTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "AP3Zyj3M1Lxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "E1XXoD0f1LmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "30ucUtcS1LiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans().setK(2).setSeed(1998)\n",
        "model = kmeans.fit(df)"
      ],
      "metadata": {
        "id": "ZBtCv-ElHbZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.transform(df)"
      ],
      "metadata": {
        "id": "BJj9ewv_HbX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = ClusteringEvaluator()"
      ],
      "metadata": {
        "id": "dqksHKS9HbWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette = evaluation.evaluate(pred)\n",
        "print(f\"Silhouette with squared euclidean distance: {silhouette}\")"
      ],
      "metadata": {
        "id": "KkFRpOdHHbSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centers = model.clusterCenters()\n",
        "print(\"Cluster Centers:\")\n",
        "print(\"=================\")\n",
        "for center in centers:\n",
        "  print(center)"
      ],
      "metadata": {
        "id": "uJpZgg0LHbOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Random Forest with data sample_libsvm_data.txt ⛹\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NVAAP-3noBOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "Q1_sSmSppsIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark.sql import SparkSession\n",
        "spark_S = SparkSession.builder.appName(\"Forest\").getOrCreate()"
      ],
      "metadata": {
        "id": "3A7w1Mq5HbGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_libsvm = spark_S.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")"
      ],
      "metadata": {
        "id": "jxt4nnQ7HbJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_libsvm.show()"
      ],
      "metadata": {
        "id": "KMO40aNUsvvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_libsvm.printSchema()"
      ],
      "metadata": {
        "id": "9ryB_IwwpPWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_libsvm.show()"
      ],
      "metadata": {
        "id": "UBBQCtI6pPTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test and Train splining step"
      ],
      "metadata": {
        "id": "GKAEuewip6Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(Mytrain, Mytest) = df_libsvm.randomSplit([0.75, 0.25], seed=1998)"
      ],
      "metadata": {
        "id": "XqJ5XxGOpPPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Test sample :++++++++++\")\n",
        "\n",
        "Mytest.show()\n",
        "\n",
        "#print(\"\\n Scheme:++++++++++\\n\",Mytest.schema())\n",
        "print(\"\\n Train sample :++++++++++\")\n",
        "Mytrain.show()\n",
        "#print(\"\\n Scheme :++++++++++\\n\",Mytrain.schema())\n"
      ],
      "metadata": {
        "id": "8gag9QI4pPMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelisation's step"
      ],
      "metadata": {
        "id": "Uh3239qora-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20,seed=1998)"
      ],
      "metadata": {
        "id": "m3xi6hyapPH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mymodel = rf.fit(Mytrain)"
      ],
      "metadata": {
        "id": "vBaCvAX1roox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Mymodel.transform(Mytest)"
      ],
      "metadata": {
        "id": "0EQs11Fhromb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.printSchema()"
      ],
      "metadata": {
        "id": "JG28e8LProfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.select(\"prediction\", \"label\", \"features\").show(5)"
      ],
      "metadata": {
        "id": "fqy7R6dlroUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation's step"
      ],
      "metadata": {
        "id": "UwNMJUYgtaF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
        "                                         predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "_3qS1B4etlAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = eval.evaluate(pred)"
      ],
      "metadata": {
        "id": "TZ5TN9QYtqHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Error = %g\" % (1.0 - acc))"
      ],
      "metadata": {
        "id": "zLKbJxCNtrGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mymodel.featureImportances"
      ],
      "metadata": {
        "id": "vmlLOvL9ts5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Boosting With Spark for ML\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LXSY4fKkuJgi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2nGI6y-lwq3"
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6V4UUIXmghD"
      },
      "source": [
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8R36fQAmiWJ"
      },
      "source": [
        "model = gbt.fit(Mytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTMHSAonm5Oj"
      },
      "source": [
        "pred = model.transform(Mytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzPYr8r2m7sx"
      },
      "source": [
        "pred.select(\"prediction\", \"label\", \"features\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0muS4ERxnAo-"
      },
      "source": [
        "eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "acc = eval.evaluate(pred)\n",
        "print(\"Test Error = %g\" % (1.0 - acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N-pgzi9murUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuBAmQHL2vXh"
      },
      "source": [
        "## Tree Methods with PySpark\n",
        "1. Single Decision Tree\n",
        "1. Random Forest\n",
        "1. Gradient Boosted Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxHdtYJ7nOf7"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark_tree = SparkSession.builder.appName(\"trees\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Uu4nY44pLu"
      },
      "source": [
        "df_tree = spark.read.csv(\"/content/college.csv\", inferSchema=True, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7EKhh7O4teO"
      },
      "source": [
        "df_tree.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCf502xw5GK3"
      },
      "source": [
        "df_tree.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pxFNfMtuvYRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMm8Udal5EXo"
      },
      "source": [
        "# Formatting for Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-fQbbcB5CTI"
      },
      "source": [
        "# \"label\", \"features\"\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l9yFfNk5jUc"
      },
      "source": [
        "df_tree.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL7wctqo5V63"
      },
      "source": [
        "df_tree.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcceDpLR5aO0"
      },
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=['Apps',\n",
        " 'Accept',\n",
        " 'Enroll',\n",
        " 'Top10perc',\n",
        " 'Top25perc',\n",
        " 'F_Undergrad',\n",
        " 'P_Undergrad',\n",
        " 'Outstate',\n",
        " 'Room_Board',\n",
        " 'Books',\n",
        " 'Personal',\n",
        " 'PhD',\n",
        " 'Terminal',\n",
        " 'S_F_Ratio',\n",
        " 'perc_alumni',\n",
        " 'Expend',\n",
        " 'Grad_Rate'          \n",
        "    ],\n",
        "    outputCol=\"features\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i96o3Zcp5zdG"
      },
      "source": [
        "output = assembler.transform(df_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6E-fj_R6H7s"
      },
      "source": [
        "# String Variables (Private)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPxGjsm86G5h"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSKIWKJp6M6D"
      },
      "source": [
        "indexer = StringIndexer(inputCol=\"Private\", outputCol=\"PrivateIndexer\")\n",
        "output_fixed = indexer.fit(output).transform(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwIN9KS6aoe"
      },
      "source": [
        "df_final = output_fixed.select(\"features\", \"PrivateIndexer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCptatjo60bf"
      },
      "source": [
        "train, test = df_final.randomSplit([0.7, 0.3], seed=1998)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5vHh5OK66ZM"
      },
      "source": [
        "# Tree Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nao7hys65wz"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-tu65V7JUs"
      },
      "source": [
        "## CREATE Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATFKKoMr7IZV"
      },
      "source": [
        "dtc = DecisionTreeClassifier(labelCol=\"PrivateIndexer\", featuresCol=\"features\")\n",
        "rfc = RandomForestClassifier(labelCol=\"PrivateIndexer\", featuresCol=\"features\")\n",
        "gbt = GBTClassifier(labelCol=\"PrivateIndexer\", featuresCol=\"features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl3S4CQz7Y6m"
      },
      "source": [
        "dtc_model = dtc.fit(train)\n",
        "rfc_model = rfc.fit(train)\n",
        "gbt_model = gbt.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV8MSude71g1"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNfI3iuB7iYK"
      },
      "source": [
        "dtc_pred = dtc_model.transform(test)\n",
        "rfc_pred = rfc_model.transform(test)\n",
        "gbt_pred = gbt_model.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P17RRuoO70CM"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGr2KfOb7y_l"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8IhNGMn76N6"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PrivateIndexer\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRj3g7y-8G4M"
      },
      "source": [
        "dtc_acc = evaluator.evaluate(dtc_pred)\n",
        "rfc_acc = evaluator.evaluate(rfc_pred)\n",
        "gbt_acc = evaluator.evaluate(gbt_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qVkFO758W3M"
      },
      "source": [
        "print(\"-\"*10)\n",
        "print(f\"DT Acc: {dtc_acc}\")\n",
        "print(\"-\"*10)\n",
        "print(f\"RFC Acc: {rfc_acc}\")\n",
        "print(\"-\"*10)\n",
        "print(f\"GBT Acc: {gbt_acc}\")\n",
        "print(\"-\"*10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Thinks . Best regards Cedarta DONOU \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fXQXROILwPOp"
      }
    }
  ]
}